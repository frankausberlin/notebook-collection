{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankausberlin/notebook-collection/blob/main/snippetpearls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4CMbxUvLJTW"
      },
      "source": [
        "**SnippetPearls**\n",
        "\n",
        "This is a jupyter notebook with several and I hope useful code snippets around very interesting technologies.\n",
        "\n",
        "\n",
        "PS.\n",
        "\n",
        "There are problems with the tab-widget from ipywidgets. In some constellations it will not be rendered (local runtime, chrome on windows, maybe more). But it works correctly (it just draw the content one after the other and not in tabs)\n",
        "\n",
        "you can look here: https://github.com/googlecolab/colabtools/issues/3105\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E9YuuXaP7JD_"
      },
      "outputs": [],
      "source": [
        "# colab forms\n",
        "#\n",
        "#@title       command shell { form-width: \"300px\" }\n",
        "#@markdown    * using [jQuery Terminal](https://terminal.jcubic.pl/) - example on [github](https://github.com/alessandrobessi/colab-shell)\n",
        "#\n",
        "#\n",
        "%matplotlib inline\n",
        "import                            os\n",
        "from   google.colab       import  widgets, output\n",
        "from   IPython.display    import  display, HTML, JSON\n",
        "from   subprocess         import  getoutput\n",
        "\n",
        "width  = 800 #@param {type: \"slider\", min: 400, max: 1200, step: 100}\n",
        "height = 400 #@param {type: \"slider\", min: 100, max: 800, step: 100}\n",
        "printHistory = False #@param {type:\"boolean\"}\n",
        "\n",
        "# function for invoke-callback-mechanism\n",
        "def shell(command):\n",
        "  # print history an reselect command tab\n",
        "  if printHistory:\n",
        "    with tabs.output_to('history'): print(command)\n",
        "    with tabs.output_to('command'): pass\n",
        "\n",
        "  # catch cd-command \n",
        "  if command.startswith('cd'):\n",
        "    path = command.strip().split(maxsplit=1)[1]\n",
        "    os.chdir(path)\n",
        "    return JSON([''])\n",
        "\n",
        "  # all other commands\n",
        "  return JSON([getoutput(command)])\n",
        "\n",
        "# register to invoke\n",
        "output.register_callback('shell', shell)\n",
        "\n",
        "# the tabs\n",
        "tabs = widgets.TabBar(['command','history'])\n",
        "\n",
        "# create command tab using javascript with 'display(HTML(...'\n",
        "with tabs.output_to('command'): display(HTML('''\n",
        "  <div id=term_demo></div>\n",
        "  <script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "  <script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "  <link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "  <script>\n",
        "    $('#term_demo').terminal(async function(command) {\n",
        "        if (command !== '') {\n",
        "            try {\n",
        "                let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
        "                let out = res.data['application/json'][0]\n",
        "                this.echo(new String(out))\n",
        "            } catch(e) {\n",
        "                this.error(new String(e));\n",
        "            }\n",
        "        } else {\n",
        "            this.echo('');\n",
        "        }\n",
        "    }, {\n",
        "        greetings: 'Welcome to Colab Shell',\n",
        "        name: 'colab_shell',\n",
        "        height: '''+str(height)+''', \n",
        "        width: '''+str(width)+''',\n",
        "        prompt: 'colab > '\n",
        "    });\n",
        "  </script>'''))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUugO9cWzX4h",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title image search { form-width: \"300px\" }\n",
        "#@markdown This little snippet does a picture search with DuckDuckGo (jpg, png, gif, bmp) and show the results (thumbnails). \n",
        "#@markdown * It creates a folder content/images (local runtime: ~/labor/content/images) and there a new folder for every search.\n",
        "#@markdown * The image thumbnails (and optional the images) will be downloaded in the search folder. \n",
        "#@markdown * It will generate a bash script (easy remove bad pictures) for downloading the images later (or again).\n",
        "\n",
        "import                            time, json, re, ipywidgets, os, \\\n",
        "                                  requests, matplotlib\n",
        "from matplotlib           import  pyplot as plt\n",
        "from urllib.parse         import  urlencode, quote, urlparse, urlunparse\n",
        "from urllib.request       import  build_opener, Request\n",
        "from urllib.error         import  HTTPError, URLError\n",
        "from google.colab         import  widgets\n",
        "from PIL                  import  Image\n",
        "from tqdm                 import  tqdm\n",
        "\n",
        "query                     = 'happy dog' #@param {type:\"string\"}\n",
        "results                   = 50 #@param {type: \"slider\", min: 1, max: 999, step: 1}\n",
        "downloadImages            = False #@param {type:\"boolean\"}\n",
        "                            #@markdown **thumbnails display**\n",
        "columns                   = 5 #@param {type: \"slider\", min: 1, max: 20, step: 1}\n",
        "rows                      = 2 #@param {type: \"slider\", min: 1, max: 100, step: 1}\n",
        "\n",
        "##########################################################################################################\n",
        "########################## reversed from https://course.fast.ai/ #########################################\n",
        "##########################################################################################################\n",
        "url_default_headers = {\n",
        "    \"Accept\":\n",
        "    \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Cache-Control\": \"max-age=0\",\n",
        "    \"Sec-Fetch-Dest\": \"document\",\n",
        "    \"Sec-Fetch-Mode\": \"navigate\",\n",
        "    \"Sec-Fetch-Site\": \"none\",\n",
        "    \"Sec-Fetch-User\": \"?1\",\n",
        "    \"Upgrade-Insecure-Requests\": \"1\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
        "}\n",
        "\n",
        "ExceptionsHTTP = {}\n",
        "\n",
        "def urlquote(url):\n",
        "    \"Update url's path with `urllib.parse.quote`\"\n",
        "    subdelims = \"!$&'()*+,;=\"\n",
        "    gendelims = \":?#[]@\"\n",
        "    safe = subdelims+gendelims+\"%/\"\n",
        "    p = list(urlparse(url))\n",
        "    p[2] = quote(p[2], safe=safe)\n",
        "    for i in range(3,6): p[i] = quote(p[i], safe=safe)\n",
        "    return urlunparse(p)\n",
        "\n",
        "def loads(s, **kw):\n",
        "    \"Same as `json.loads`, but handles `None`\"\n",
        "    if not s: return {}\n",
        "    try: import ujson as json\n",
        "    except ModuleNotFoundError: import json\n",
        "    return json.loads(s, **kw)\n",
        "\n",
        "def urlwrap(url, data=None, headers=None):\n",
        "    \"Wrap `url` in a urllib `Request` with `urlquote`\"\n",
        "    return url if isinstance(url,Request) else Request(urlquote(url), data=data, headers=headers or {})\n",
        "\n",
        "def urlopener():\n",
        "    _opener = build_opener()\n",
        "    _opener.addheaders = list(url_default_headers.items())\n",
        "    return _opener\n",
        "\n",
        "def urlopen(url, data=None, headers=None, timeout=None, **kwargs):\n",
        "    \"Like `urllib.request.urlopen`, but first `urlwrap` the `url`, and encode `data`\"\n",
        "    if kwargs and not data: data=kwargs\n",
        "    if data is not None:\n",
        "        if not isinstance(data, (str,bytes)): data = urlencode(data)\n",
        "        if not isinstance(data, bytes): data = data.encode('ascii')\n",
        "    try: return urlopener().open(urlwrap(url, data=data, headers=headers), timeout=timeout)\n",
        "    except HTTPError as e: \n",
        "        e.msg += f\"\\n====Error Body====\\n{e.read().decode(errors='ignore')}\"\n",
        "        raise\n",
        "\n",
        "def urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, timeout=None, **kwargs):\n",
        "    \"Retrieve `url`, using `data` dict or `kwargs` to `POST` if present\"\n",
        "    try:\n",
        "        with urlopen(url, data=data, headers=headers, timeout=timeout, **kwargs) as u: res,hdrs = u.read(),u.headers\n",
        "    except HTTPError as e:\n",
        "        if 400 <= e.code < 500: raise ExceptionsHTTP[e.code](e.url, e.hdrs, e.fp) from None\n",
        "        else: raise\n",
        "\n",
        "    if decode: res = res.decode()\n",
        "    if return_json: res = loads(res)\n",
        "    return (res,dict(hdrs)) if return_headers else res\n",
        "\n",
        "def isddg(term, max_images=200):\n",
        "    \"Search for `term` with DuckDuckGo and return a unique urls of about `max_images` images\"\n",
        "    assert max_images<1000\n",
        "    url = 'https://duckduckgo.com/'\n",
        "    res = urlread(url,data={'q':term})\n",
        "    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n",
        "    assert searchObj\n",
        "    requestUrl = url + 'i.js'\n",
        "    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n",
        "    xu,data = list(),{'next':1} # little change: don't use the mysterious L class\n",
        "    headers = dict(referer='https://duckduckgo.com/')\n",
        "    while len(xu)<max_images and 'next' in data:\n",
        "        try:\n",
        "            res = urlread(requestUrl, data=params, headers=headers)\n",
        "            data = json.loads(res) if res else {}\n",
        "            for i in range(len(data['results'])):\n",
        "              xu.append(data['results'][i])\n",
        "            requestUrl = url + data['next']\n",
        "        except (URLError,HTTPError): pass\n",
        "        time.sleep(1)\n",
        "    return xu[:max_images]\n",
        "##########################################################################################################\n",
        "##########################################################################################################\n",
        "##########################################################################################################\n",
        "\n",
        "# download the ddg results page (links)\n",
        "links                 = isddg (query,results)\n",
        "if downloadImages:    print (f'checking {len(links)} links - start download thumbnails and images')\n",
        "else:                 print (f'checking {len(links)} links - start download thumbnails')\n",
        "\n",
        "# mkdir\n",
        "qfolder       = query.replace (' ','')\n",
        "if os.path.exists('/content'):\n",
        "  os.makedirs   ('/content/images',exist_ok=True)\n",
        "  os.makedirs   (f'/content/images/{qfolder}',exist_ok=True)\n",
        "  os.chdir      (f'/content/images/{qfolder}')\n",
        "else:\n",
        "  os.makedirs   (f'{os.path.expanduser(\"~\")}/labor/content',exist_ok=True)\n",
        "  os.makedirs   (f'{os.path.expanduser(\"~\")}/labor/content/images',exist_ok=True)\n",
        "  os.makedirs   (f'{os.path.expanduser(\"~\")}/labor/content/images/{qfolder}',exist_ok=True)\n",
        "  os.chdir      (f'{os.path.expanduser(\"~\")}/labor/content/images/{qfolder}')\n",
        "\n",
        "\n",
        "# inits\n",
        "pos, bad, thumbs, bash = 0, 0, [], f'#!/bin/bash\\nmkdir -p {qfolder}\\n'\n",
        "\n",
        "# loop the links\n",
        "for all in tqdm(links): \n",
        "\n",
        "  # extract infos\n",
        "  url  = all['image']\n",
        "  turl = all['thumbnail']\n",
        "  ext  = url.split('.')[-1]\n",
        "  if '?' in ext: ext = ext.split('?')[0]\n",
        "  dest = f\"{qfolder}{pos-bad}.{ext}\"\n",
        "  pos+=1\n",
        "\n",
        "  # check extension\n",
        "  if ext.lower() in 'jpg png gif bmp':\n",
        "\n",
        "    # download image und thumbnail\n",
        "    try:\n",
        "\n",
        "      # image\n",
        "      if downloadImages:\n",
        "        im = Image.open(requests.get(url, stream = True).raw)\n",
        "        im.save(dest)\n",
        "\n",
        "      # bash script entry\n",
        "      bash += f'# Picture {dest}\\ncurl \"{url}\" --output {qfolder}/{dest}\\n' \n",
        "\n",
        "      # thumbnail\n",
        "      im = Image.open(requests.get(turl, stream = True).raw)\n",
        "      im.save('thumb'+dest) \n",
        "      thumbs.append('thumb'+dest)\n",
        "\n",
        "    # count bad links\n",
        "    except Exception:\n",
        "      bad += 1\n",
        "  else:\n",
        "    bad += 1\n",
        "\n",
        "# output infos\n",
        "if not downloadImages:  txt = f'downloaded {len(thumbs)} thumbnails'\n",
        "else:                   txt = f'downloaded {len(thumbs)} images and thumbnails'   \n",
        "print                   (f'\\n\\n\\x1b[32m{txt}\\x1b[0m - \\x1b[91mfound {bad} bad links!!!\\x1b[0m')\n",
        "\n",
        "# write bash \n",
        "if os.path.exists('/content'):\n",
        "  print    (f'Create bash script: \\x1b[34m/content/images/dl_{qfolder}.sh\\x1b[0m')\n",
        "  open     (f'/content/images/dl_{qfolder}.sh', 'w').write(bash)\n",
        "else:\n",
        "  print    (f'Create bash script: \\x1b[34m~/labor/content/images/dl_{qfolder}.sh\\x1b[0m')\n",
        "  open     (f'{os.path.expanduser(\"~\")}/labor/content/images/dl_{qfolder}.sh', 'w').write(bash)\n",
        "\n",
        "\n",
        "# build the thumbnails tabs\n",
        "titles, len_thumbs = [], len(thumbs)\n",
        "for i in range(0,len_thumbs,(columns*rows)):\n",
        "  x = ((i//(columns*rows))+1)*(columns*rows)-1\n",
        "  if x >= len_thumbs: x = len_thumbs-1\n",
        "  titles.append(f'{i}-{x}')\n",
        "tabs = widgets.TabBar(titles)\n",
        "\n",
        "# title font\n",
        "matplotlib.rc('font', **{'sans-serif':    'DejaVu Sans',\n",
        "                          'family':        'sans-serif',\n",
        "                          'weight':        'bold', \n",
        "                          'size':          (columns+10 if columns > 12 else 16) })  \n",
        "\n",
        "# fill the tabs\n",
        "for i,t in enumerate(titles):\n",
        "  with tabs.output_to (t): \n",
        "    \n",
        "    # figure dimension (inch)\n",
        "    fig = plt.figure(figsize=(4*columns, 4.25*rows))\n",
        "    \n",
        "    # all images for the tab i\n",
        "    for j in range(columns*rows):\n",
        "      x = i*(columns*rows)+j\n",
        "\n",
        "      # subplot image\n",
        "      if x < len_thumbs:\n",
        "        fig.add_subplot(rows, columns, j+1, xticks=[], yticks=[], title=f'{x}')\n",
        "        im = Image.open (thumbs[x])\n",
        "        plt.imshow(im)\n",
        "\n",
        "# cd to image folder         \n",
        "if os.path.exists('/content'): os.chdir (f'/content/images')\n",
        "else: os.chdir (f'{os.path.expanduser(\"~\")}/labor/content/images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6GtFFAF8xa5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title debug { form-width: \"700px\" }\n",
        "#@markdown * When an error happens you can run **%debug** in a new code cell.\n",
        "#@markdown * Or you set a breakpoint with ```from IPython.core.debugger import Pdb; Pdb().set_trace()```\n",
        "#@markdown * Some commands:<br><table align='left'><tr><td><b>'q': quit</b> - Exit the debugger.<br>_</td><td><b>'c': continue</b> - Run to the next breakpoint.<br>_</td><td><b>'l' : list</b> - Shows 11 lines of code<br>around the actual position.</td></tr><tr><td><b>'n': next</b> - Run the next line<br>in current function.</td><td><b>'s': step</b> - step in to a function.<br>_</td><td><b>'r' : return</b> - Continue execution until<br>the current function returns.</td></tr></tr><tr><td><b>'h': help</b> - Shows help for a command<br>or all (if none parameter)</td><td><b>'b': breakpoint</b> - Makes a breakpoint for<br>a function or codeline (nr).</td><td><b>'cl' : clear</b> - Deletes breakpoint(s)<br>_</td></tr></table>\n",
        "\n",
        "def f (x):\n",
        "  ret = x / 7\n",
        "\n",
        "  # breakpoint\n",
        "  from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "  \n",
        "  return ret\n",
        "\n",
        "f(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MTxVBRM-DDX0"
      },
      "outputs": [],
      "source": [
        "#@title [ANSI escape code](https://en.wikipedia.org/wiki/ANSI_escape_code)\n",
        "#@markdown * selection - [from here](https://gist.github.com/iansan5653/c4a0b9f5c30d74258c5f132084b78db9)\n",
        "\n",
        "print('\\x1b[0m Reset / Normal \\x1b[0m')\n",
        "print('\\x1b[1m Bold or increased intensity \\x1b[0m')\n",
        "print('\\x1b[3m Italic \\x1b[0m')\n",
        "print('\\x1b[4m Underline \\x1b[0m')\n",
        "\n",
        "print(' Basic Foreground Colors:')\n",
        "print('\\t\\x1b[30m Black foreground\\x1b[0m')\n",
        "print('\\t\\x1b[31m Red foreground\\x1b[0m')\n",
        "print('\\t\\x1b[32m Green foreground\\x1b[0m')\n",
        "print('\\t\\x1b[33m Yellow foreground\\x1b[0m')\n",
        "print('\\t\\x1b[34m Blue foreground\\x1b[0m')\n",
        "print('\\t\\x1b[35m Magenta foreground\\x1b[0m')\n",
        "print('\\t\\x1b[36m Cyan foreground\\x1b[0m')\n",
        "print('\\t\\x1b[37m White foreground\\x1b[0m')\n",
        "print('\\t\\x1b[39m Default foreground color \\x1b[0m')\n",
        "\n",
        "print(' Basic Background Colors:')\n",
        "print('\\t\\x1b[40m Black background\\x1b[0m')\n",
        "print('\\t\\x1b[41m Red background\\x1b[0m')\n",
        "print('\\t\\x1b[42m Green background\\x1b[0m')\n",
        "print('\\t\\x1b[43m Yellow background\\x1b[0m')\n",
        "print('\\t\\x1b[44m Blue background\\x1b[0m')\n",
        "print('\\t\\x1b[45m Magenta background\\x1b[0m')\n",
        "print('\\t\\x1b[46m Cyan background\\x1b[0m')\n",
        "print('\\t\\x1b[47m White background\\x1b[0m')\n",
        "print('\\t\\x1b[49m Default background color \\x1b[0m')\n",
        "\n",
        "print(' Bright Foreground Colors:')\n",
        "print('\\t\\x1b[90m Bright Black foreground\\x1b[0m')\n",
        "print('\\t\\x1b[91m Bright Red foreground\\x1b[0m')\n",
        "print('\\t\\x1b[92m Bright Green foreground\\x1b[0m')\n",
        "print('\\t\\x1b[93m Bright Yellow foreground\\x1b[0m')\n",
        "print('\\t\\x1b[94m Bright Blue foreground\\x1b[0m')\n",
        "print('\\t\\x1b[95m Bright Magenta foreground\\x1b[0m')\n",
        "print('\\t\\x1b[96m Bright Cyan foreground\\x1b[0m')\n",
        "print('\\t\\x1b[97m Bright White foreground\\x1b[0m')\n",
        "\n",
        "print(' Bright Background Colors:')\n",
        "print('\\t\\x1b[100m Bright Black background\\x1b[0m')\n",
        "print('\\t\\x1b[101m Bright Red background\\x1b[0m')\n",
        "print('\\t\\x1b[102m Bright Green background\\x1b[0m')\n",
        "print('\\t\\x1b[103m Bright Yellow background\\x1b[0m')\n",
        "print('\\t\\x1b[104m Bright Blue background\\x1b[0m')\n",
        "print('\\t\\x1b[105m Bright Magenta background\\x1b[0m')\n",
        "print('\\t\\x1b[106m Bright Cyan background\\x1b[0m')\n",
        "print('\\t\\x1b[107m Bright White background\\x1b[0m')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZIvV_Ux-FG1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title gpu test { form-width: \"300px\" }\n",
        "#@markdown * the **tensorflow** [mnist example]( https://keras.io/examples/vision/mnist_convnet/)\n",
        "\n",
        "from   matplotlib         import  pyplot as plt\n",
        "from   google.colab       import  widgets\n",
        "from   google.colab       import  output\n",
        "from   tensorflow         import  keras\n",
        "from   tensorflow.keras   import  layers\n",
        "import                            numpy as np, matplotlib,\\\n",
        "                                  ipywidgets, tensorflow as tf\n",
        "# free memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# cell-output design\n",
        "tabs      = widgets.TabBar(['overview','model','training','scores','fails'])\n",
        "columns   = 10\n",
        "rows      = 10\n",
        "\n",
        "# inits / forms\n",
        "num_classes   = 10\n",
        "input_shape   = (28, 28, 1)\n",
        "batch_size    = 137 #@param {type: \"slider\", min: 1, max: 200}\n",
        "epochs        = 10  #@param {type: \"slider\", min: 1, max: 20}\n",
        "learning_rate = \"0.0025\" #@param [\"0.9\", \"0.5\", \"0.2\", \"0.1\", \"0.01\", \"0.001\", \"0.0001\"] {allow-input: true}\n",
        "matplotlib.rc ('image', cmap='Greys')\n",
        "\n",
        "\n",
        "# button function\n",
        "button_plotoverview = ipywidgets.Button(description=\"plot overview\")\n",
        "def on_plotoverview_clicked(b):\n",
        "  # disable button\n",
        "  b.disabled = True\n",
        "\n",
        "  # do the plot\n",
        "  plot_overview ()\n",
        "\n",
        "def plot_overview ():\n",
        "  with tabs.output_to ('overview'):\n",
        "    # figure dimension\n",
        "    fig = plt.figure(figsize=(1.2*columns, 1.5*rows))\n",
        "\n",
        "    # plot \n",
        "    for i in range(columns*rows):\n",
        "      fig.add_subplot(rows, columns, i+1, xticks=[], yticks=[], title=f'{np.argmax(y_train[i])}')\n",
        "      plt.imshow(x_train[i].reshape (28,28))\n",
        "\n",
        "\n",
        "# overview-tab\n",
        "with tabs.output_to ('overview'):\n",
        "  # the data, split between train and test sets\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "  # Scale images to the [0, 1] range\n",
        "  x_train = x_train.astype(\"float32\") / 255\n",
        "  x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "  # Make sure images have shape (28, 28, 1)\n",
        "  x_train = np.expand_dims(x_train, -1)\n",
        "  x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "  # convert class vectors to binary class matrices\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "  # binding and display\n",
        "  button_plotoverview.on_click(on_plotoverview_clicked)\n",
        "  display(button_plotoverview)\n",
        "\n",
        "\n",
        "# model-tab\n",
        "with tabs.output_to ('model'):\n",
        "  # generate model\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=input_shape),\n",
        "          layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Flatten(),\n",
        "          layers.Dropout(0.5),\n",
        "          layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # print infos\n",
        "  print(\"x_train shape:\", x_train.shape)\n",
        "  print(\"x_test shape: \", x_test.shape,\"\\n\")\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "# button function\n",
        "button_starttraining = ipywidgets.Button(description=\"start training\")\n",
        "def on_starttraining_clicked(b):\n",
        "  # disable button\n",
        "  b.disabled = True\n",
        "\n",
        "  # start training\n",
        "  if tf.test.gpu_device_name() == '':  print('\\t\\x1b[31m Please activate gpu acceleration\\x1b[0m')\n",
        "  else: start_training()\n",
        "\n",
        "# training-tab\n",
        "with tabs.output_to ('training'):\n",
        "  # binding and display\n",
        "  button_starttraining.on_click(on_starttraining_clicked)\n",
        "  display(button_starttraining)\n",
        "\n",
        "\n",
        "def start_training ():\n",
        "  # start training in training-tab\n",
        "  with tabs.output_to ('training'):\n",
        "    print(\">accelerator\",tf.test.gpu_device_name())\n",
        "    print('>batch_size',batch_size)\n",
        "    print('>epochs',epochs)\n",
        "    print('>learning_rate',learning_rate)\n",
        "    model.compile ( loss      = \"categorical_crossentropy\", \n",
        "                    optimizer = tf.keras.optimizers.Adam(learning_rate=float(learning_rate)),\n",
        "                    metrics   = [\"accuracy\"])\n",
        "   \n",
        "    history = model.fit ( x_train, y_train,\n",
        "                          batch_size        = batch_size, \n",
        "                          epochs            = epochs, \n",
        "                          validation_split  = 0.1)\n",
        "    \n",
        "  # draw scores-tab\n",
        "  with tabs.output_to ('scores'):\n",
        "    print('>please wait for evaluate loss and accuracy ...\\n')\n",
        "    for all in history.history: plt.plot(history.history[all])\n",
        "    plt.legend(history.history.keys())    \n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "\n",
        "  # draw fails-tab\n",
        "  with tabs.output_to ('fails'):\n",
        "\n",
        "    # looking for fails\n",
        "    predictions, fails, total = model.predict (x_test), [], 0\n",
        "    for i in range (len(predictions)):\n",
        "      if (np.argmax (predictions[i]) != np.argmax (y_test[i])):\n",
        "        fails.append ({'pos':       i,\n",
        "                      'expected':  np.argmax (y_test[i]),\n",
        "                      'predicted': np.argmax (predictions[i])} )\n",
        "        total += 1\n",
        "\n",
        "    # header\n",
        "    failCount = min(columns*rows,len(fails))\n",
        "    print (f'fails total: {total} ({len(predictions)})')\n",
        "    print ('title: \\x1b[92mexpected \\x1b[30m/ \\x1b[91mpredicted\\x1b[30m')\n",
        "    print (f'first {failCount} ...')\n",
        "    \n",
        "    # subplots\n",
        "    fig = plt.figure(figsize=(1.2*columns, 1.5*rows))\n",
        "    for i in range (failCount):\n",
        "      fig.add_subplot (rows, columns, i+1, xticks=[], yticks=[])\n",
        "      plt.title (f\"  {fails[i]['expected']}\",    color='green', loc='left')\n",
        "      plt.title (\"/\",                          color='black', loc='center')\n",
        "      plt.title (f\"{fails[i]['predicted']}  \",   color='red',   loc='right')\n",
        "      plt.imshow(x_test[fails[i]['pos']].reshape(28,28))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **gpu test**\n",
        "#@markdown * a **numba** example from [here]( https://github.com/Zhyrek/numba) shows a task that was solved once with cpu and once with gpu\n",
        "from numba import cuda\n",
        "from matplotlib import pyplot as plt\n",
        "import time, numpy as np\n",
        "\n",
        "# free memory\n",
        "cuda.close()\n",
        "\n",
        "\n",
        "def cahnallen_CPU_dirichlet(array, steps):\n",
        "    phi = array.copy()\n",
        "    M = 0.2\n",
        "    dt = 1.\n",
        "    dx = 1.\n",
        "    idx2 = 1./(dx*dx)\n",
        "    e = 1.\n",
        "    e2 = e*e\n",
        "    W = 0.2\n",
        "    for i in range(steps):\n",
        "        phi_xm = phi[0:-2,1:-1]\n",
        "        phi_xp = phi[2:,1:-1]\n",
        "        phi_ym = phi[1:-1,0:-2]\n",
        "        phi_yp = phi[1:-1,2:]\n",
        "        phi_center = phi[1:-1,1:-1]\n",
        "        phi_center += M*dt*(e2*(phi_xm+phi_xp+phi_ym+phi_yp-4*phi_center)*idx2 - W*(4*phi_center**3 - 6*phi_center**2 + 2*phi_center))\n",
        "    return phi\n",
        "        \n",
        "def cahnallen_GPU_dirichlet(array, steps):\n",
        "    \n",
        "    array_out = array.copy()\n",
        "    \n",
        "    array_gpu = cuda.to_device(array)\n",
        "    array_out_gpu = cuda.to_device(array_out)\n",
        "    \n",
        "    @cuda.jit\n",
        "    def cahnallen_kernel(c, c_out):\n",
        "        startx, starty = cuda.grid(2)      \n",
        "        stridex, stridey = cuda.gridsize(2) \n",
        "        M = 0.2\n",
        "        dt = 1.\n",
        "        dx = 1.\n",
        "        idx2 = 1./(dx*dx)\n",
        "        e = 1.\n",
        "        e2 = e*e\n",
        "        W = 0.2\n",
        "        for i in range(starty+1, c.shape[0]-1, stridey):\n",
        "            for j in range(startx+1, c.shape[1]-1, stridex):\n",
        "                c_out[i][j] = c[i][j] + M*dt*((e2*(c[i+1][j]+c[i-1][j]+c[i][j+1]+c[i][j-1]-4*c[i][j]))*idx2 - W*(4*c[i][j]**3 - 6*c[i][j]**2 + 2*c[i][j])) \n",
        "            \n",
        "    threads = (8,8)\n",
        "    blocks = (8,8)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        cahnallen_kernel[threads, blocks](array_gpu, array_out_gpu)\n",
        "        cuda.synchronize()\n",
        "        array_gpu, array_out_gpu = array_out_gpu, array_gpu\n",
        "\n",
        "    c = array_gpu.copy_to_host()\n",
        "    return c\n",
        "\n",
        "phi = 0.01*np.random.random([1000,1000])+0.495\n",
        "\n",
        "print ('wait 30 - 60 seconds')\n",
        "\n",
        "t0 = time.time()\n",
        "gpu_result = cahnallen_GPU_dirichlet(phi, 1000)\n",
        "t1 = time.time()\n",
        "plt.imshow(gpu_result, cmap = \"bwr\")\n",
        "plt.show()\n",
        "print(\"GPU Time: \"+str(t1-t0))\n",
        "\n",
        "t0 = time.time()\n",
        "cpu_result = cahnallen_CPU_dirichlet(phi, 1000)   \n",
        "t1 = time.time()\n",
        "plt.imshow(cpu_result, cmap = \"bwr\")\n",
        "plt.show()\n",
        "print(\"CPU Time: \"+str(t1-t0))\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ir5Q25IzlDGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OkADQaAwdk5H"
      },
      "outputs": [],
      "source": [
        "#@markdown **gpu test**\n",
        "#@markdown * mnist **pytorch** (fastai) example from [Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook)\n",
        "\n",
        "try:\n",
        "    import fastbook                     \n",
        "except ImportError:\n",
        "  !pip install -Uqq fastbook\n",
        "  import fastbook\n",
        "from fastbook import *\n",
        "from fastai.vision.all import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# free memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "path = untar_data(URLs.MNIST)\n",
        "dls = ImageDataLoaders.from_folder(path, train='training', valid='testing')\n",
        "\n",
        "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
        "                    loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy)\n",
        "\n",
        "learn.fit_one_cycle(1, 0.1)\n",
        "\n",
        "print('one image')\n",
        "img_files = get_image_files(path/\"testing\")\n",
        "img = PILImage.create(img_files[7000])\n",
        "display(img)\n",
        "print ('predict:',learn.predict(img))\n",
        "\n",
        "print ('train / valid')\n",
        "dls.train.show_batch(max_n=4, nrows=1)\n",
        "dls.valid.show_batch(max_n=4, nrows=1)\n",
        "\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_top_losses(4, nrows=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title hosted runtime\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM - '.format(ram_gb),end='')\n",
        "if ram_gb < 20: print('Not using a high-RAM runtime')\n",
        "else:           print('You are using a high-RAM runtime!')\n",
        "print('')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0: print('Not connected to a GPU')\n",
        "else:                            print(gpu_info)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ap4osOgA-7TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7xgE7-YaicX"
      },
      "source": [
        "# local runtime\n",
        "1. install cuda \n",
        "2. install docker\n",
        "3. install mamba\n",
        "```\n",
        "curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\"\n",
        "bash Mambaforge-$(uname)-$(uname -m).sh\n",
        "```\n",
        "4. create a machine learning environment with colab, jupyter, tensorflow, pytorch, numba etc. - either directly or in a container\n",
        "5. to use kaggle you have to copy the kaggle.json file in the ~/.kaggle folder (get it in your kaggle account settings).\n",
        "```\n",
        "cp ~/Downloads/kaggle.json ~/.kaggle; chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5P3_B_QeSdb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title cuda\n",
        "\n",
        "# nvidia-driver --> cudatoolkit --> cuDNN\n",
        "\"\"\"\n",
        "# https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html\n",
        "# nvidia cuDNN: \n",
        "#      + nvidia-driver\n",
        "#      |     +--> sudo add-apt-repository ppa:graphics-drivers/ppa -y\n",
        "#      |     +--> apt list -a nvidia-driver* # --> 515 (highest number)\n",
        "#      |     +--> sudo apt-get install nvidia-driver-515 # <-- 515\n",
        "#      +--cuda-toolkit\n",
        "#      |     +--> do this: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
        "#      |     +--> download: https://developer.nvidia.com/cuda-downloads\n",
        "#      +--cuDNN: \n",
        "#      |     +->> do this: https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux-deb\n",
        "#            +--> change the values correct:  'x.x.x' from downloaded file, 'X.Y' from cuda version (nvidia-smi)\n",
        "#\n",
        "# to run mnistCUDNN:\n",
        "sudo apt-get install libfreeimage3 libfreeimage-dev\n",
        "\n",
        "# nvidia cuDNN (wsl2): \n",
        "#      + nvidia-driver\n",
        "#      |     +--> sudo add-apt-repository ppa:graphics-drivers/ppa -y\n",
        "#      |     +--> apt list -a nvidia-driver* # --> 515 (highest number)\n",
        "#      |     +--> sudo apt-get install nvidia-driver-515 # <-- 515\n",
        "#      +--cuda-toolkit\n",
        "#      |     +--> do this: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
        "#      |     +--> download: https://developer.nvidia.com/cuda-downloads\n",
        "#      +--cuDNN: \n",
        "#      |     +->> do this: https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux-deb\n",
        "#            +--> change the values correct:  'x.x.x' from downloaded file, 'X.Y' from cuda version (nvidia-smi)\n",
        "#\n",
        "\n",
        "\n",
        "windows\n",
        "https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "print ('nvidia-smi\\n')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbxDWoeX3qEm"
      },
      "outputs": [],
      "source": [
        "#@title docker\n",
        "\n",
        "# docker --> nvidia-docker\n",
        "\n",
        "# docker\n",
        "\"\"\"\n",
        "sudo apt-get install ca-certificates curl gnupg lsb-release\n",
        "sudo apt-get remove docker docker-engine docker.io containerd runc    \n",
        "sudo mkdir -p /etc/apt/keyrings\n",
        "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg    \n",
        "echo \\\n",
        "  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n",
        "  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
        "sudo apt-get update\n",
        "sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n",
        "sudo service docker start  \n",
        "sudo docker run hello-world\n",
        "sudo apt install ./docker-desktop*.deb # from https://docs.docker.com/desktop/install/ubuntu/\n",
        "sudo groupadd docker\n",
        "sudo usermod -aG docker $USER\n",
        "newgrp docker\n",
        "gpg --generate-key\n",
        "pass init 7865BA9185AFA2C26C5B505669FC4F36530097C2 !!! replace with yours (output gpg)\n",
        "\"\"\"\n",
        "\n",
        "# nvidia-docker \n",
        "\"\"\"\n",
        "# from https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\n",
        "distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n",
        "      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
        "      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n",
        "            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
        "            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
        "sudo apt-get update\n",
        "curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \\\n",
        "  sudo apt-key add -sudo apt-get install -y nvidia-docker2\n",
        "sudo systemctl restart docker\n",
        "\"\"\"\n",
        "\n",
        "# dashboard\n",
        "\"\"\"\n",
        "https://amytabb.com/ts/2020-09-19/#run-test\n",
        "https://towardsdatascience.com/create-your-own-gpu-accelerated-yupyter-notebook-server-with-google-colab-using-docker-2fa14900bab5\n",
        "\n",
        "docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu-jupyter bash\n",
        "docker run --gpus all -p 8888:8888 -v /home/frank/labor/:/tf/labor/ -it --rm tensorflow/tensorflow:latest-gpu-jupyter bash\n",
        "jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "jupyter notebook --notebook-dir=\"/tf/labor/content\" --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.disable_check_xsrf=True\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print ('nvidia-smi out of the container\\n')\n",
        "print ('>docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi\\n')\n",
        "!docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyGh7tB4vCRZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ml environment { form-width: \"300px\" }\n",
        "#@markdown * tensorflow, pytorch, numba (with gpu)\n",
        "#@markdown * jupyter, scikit, pandas, scrapy, colab and more\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# run once\n",
        "mamba create --name ml python jupyter jupyter_http_over_ws pytorch torchvision matplotlib pandas pillow scrapy google-colab tqdm kaggle; mamba activate ml; pip install -Uqq fastbook; pip install tensorflow-gpu\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "\n",
        "# start jupyter notebook (copy the localhost-link)\n",
        "jupyter notebook --notebook-dir=\"~/labor/content\" --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0 \n",
        "\n",
        "# !!!ATTENTION!!! start jupyter notebook with access to local folder (no token)\n",
        "# !!!ATTENTION!!! look here for more infos: https://stackoverflow.com/questions/54998936/unable-to-connect-to-the-local-runtime-in-google-colab\n",
        "jupyter notebook --notebook-dir=\"~/labor/content\" --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.disable_check_xsrf=True\n",
        "\"\"\"\n",
        "\n",
        "import torch, numba, tensorflow as tf\n",
        "from numba import cuda\n",
        "\n",
        "print (f'pytorch    ({torch.__version__:15s}) get_device_name(0)  = {torch.cuda.get_device_name(0)}')\n",
        "print (f\"tensorflow ({tf.__version__:15s}) physical_devices[0] = {tf.config.list_physical_devices('GPU')[0]}\")\n",
        "print (f\"numba      ({numba.__version__:15s}) select_device(0)    = {cuda.select_device(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tensorboard\n",
        "#@markdown start cell:<br>\n",
        "#@markdown ```from tensorflow.keras.callbacks import TensorBoard```<br>\n",
        "#@markdown ```log_folder = 'logs'```<br>\n",
        "#@markdown ```%load_ext tensorboard```<br>\n",
        "#@markdown end cell:<br>\n",
        "#@markdown ```%tensorboard --logdir='logs' --host localhost --port 8088```<br>\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "log_folder = 'logs'\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "   tf.keras.layers.Dense(512, activation='relu'),\n",
        "   tf.keras.layers.Dropout(0.2),\n",
        "   tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='sgd', \n",
        "   loss='sparse_categorical_crossentropy',\n",
        "   metrics=['accuracy'])\n",
        "\n",
        "callbacks = [TensorBoard(log_dir=log_folder,\n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_images=True,\n",
        "                         update_freq='epoch',\n",
        "                         profile_batch=2,\n",
        "                         embeddings_freq=1)]\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=callbacks)  \n",
        "\n",
        "%tensorboard --logdir='logs' --host localhost --port 8088\n",
        "print ('for local runtime goto: http://localhost:8088/')"
      ],
      "metadata": {
        "id": "40LTArgGplqA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXUdEK50-nJX"
      },
      "source": [
        "# video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kPa97d2dMdfN"
      },
      "outputs": [],
      "source": [
        "#@markdown **record video** { form-width: \"300px\" }\n",
        "# Adapted from: https://stackoverflow.com/a/62804023/4879610\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def record_video(filename):\n",
        "  js = Javascript(\"\"\"\n",
        "    async function recordVideo() {\n",
        "      // mashes together the advanced_outputs.ipynb function provided by Colab, \n",
        "      // a bunch of stuff from Stack overflow, and some sample code from:\n",
        "      // https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API\n",
        "\n",
        "      // Optional frames per second argument.\n",
        "      const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      const stopCapture = document.createElement(\"button\");\n",
        "      capture.textContent = \"Start Recording\";\n",
        "      capture.style.background = \"green\";\n",
        "      capture.style.color = \"white\";\n",
        "\n",
        "      stopCapture.textContent = \"Stop Recording\";\n",
        "      stopCapture.style.background = \"red\";\n",
        "      stopCapture.style.color = \"white\";\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      const recordingVid = document.createElement(\"video\");\n",
        "      video.style.display = 'block';\n",
        "\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n",
        "      // create a media recorder instance, which is an object\n",
        "      // that will let you record what you stream.\n",
        "      let recorder = new MediaRecorder(stream, options);\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      // Video is a media element.  This line here sets the object which serves\n",
        "      // as the source of the media associated with the HTMLMediaElement\n",
        "      // Here, we'll set it equal to the stream.\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      // from https://stackoverflow.com/questions/62529304/is-there-any-way-to-capture-live-video-using-webcam-in-google-colab#comment114644726_62804023\n",
        "      video.muted = true;\n",
        "\n",
        "      // We're inside an async function, so this await will fire off the playing\n",
        "      // of a video. It returns a Promise which is resolved when playback has \n",
        "      // been successfully started. Since this is async, the function will be \n",
        "      // paused until this has started playing. \n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      // and now, just wait for the capture button to get clicked in order to\n",
        "      // start recording\n",
        "      await new Promise((resolve) => {\n",
        "        capture.onclick = resolve;\n",
        "      });\n",
        "      recorder.start();\n",
        "      capture.replaceWith(stopCapture);\n",
        "      // use a promise to tell it to stop recording\n",
        "      await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "      recorder.stop();\n",
        "\n",
        "      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "      let arrBuff = await recData.data.arrayBuffer();\n",
        "      \n",
        "      // stop the stream and remove the video element\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "\n",
        "      let binaryString = \"\";\n",
        "      let bytes = new Uint8Array(arrBuff);\n",
        "      bytes.forEach((byte) => {\n",
        "        binaryString += String.fromCharCode(byte);\n",
        "      })\n",
        "      return btoa(binaryString);\n",
        "\n",
        "    }\n",
        "    \"\"\")\n",
        "  try:\n",
        "    display(js)\n",
        "    data = eval_js('recordVideo({})')\n",
        "    binary = b64decode(data)\n",
        "    with open(filename, \"wb\") as video_file:\n",
        "      video_file.write(binary)\n",
        "    print(\n",
        "        f\"Finished recording video. Saved binary under filename in current working directory: {filename}\"\n",
        "    )\n",
        "  except Exception as err:\n",
        "      # In case any exceptions arise\n",
        "      print(str(err))\n",
        "\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, video_width = 300):\n",
        "  # show saved video in colab.\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "video_path = \"test.mp4\"\n",
        "record_video(video_path)\n",
        "\n",
        "\n",
        "\n",
        "show_video(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n33iVm84sQLy"
      },
      "outputs": [],
      "source": [
        "#@markdown stream video\n",
        "#https://www.quora.com/How-do-I-open-a-webcam-live-video-stream-in-Google-Colab\n",
        "\n",
        "from IPython.display import HTML, Audio \n",
        "from google.colab.output import eval_js \n",
        "from base64 import b64decode \n",
        "import numpy as np \n",
        "import io \n",
        "from PIL import Image \n",
        " \n",
        "VIDEO_HTML = \"\"\" \n",
        "<video autoplay \n",
        " width=%d height=%d style='cursor: pointer;'></video> \n",
        "<script> \n",
        " \n",
        "var video = document.querySelector('video') \n",
        " \n",
        "navigator.mediaDevices.getUserMedia({ video: true }) \n",
        "  .then(stream=> video.srcObject = stream) \n",
        "   \n",
        "var data = new Promise(resolve=>{ \n",
        "  video.onclick = ()=>{ \n",
        "    var canvas = document.createElement('canvas') \n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight] \n",
        "    canvas.width = w \n",
        "    canvas.height = h \n",
        "    canvas.getContext('2d') \n",
        "          .drawImage(video, 0, 0, w, h) \n",
        "    video.srcObject.getVideoTracks()[0].stop() \n",
        "    video.replaceWith(canvas) \n",
        "    resolve(canvas.toDataURL('image/jpeg', %f)) \n",
        "  } \n",
        "}) \n",
        "</script> \n",
        "\"\"\" \n",
        "def take_photo(filename='photo.jpg', quality=0.8, size=(400,300)): \n",
        "  display(HTML(VIDEO_HTML % (size[0],size[1],quality))) \n",
        "  data = eval_js(\"data\") \n",
        "  binary = b64decode(data.split(',')[1]) \n",
        "  f = io.BytesIO(binary) \n",
        "  return np.asarray(Image.open(f)) \n",
        " \n",
        "print ('click to take a photo...') \n",
        "img = take_photo() # click \n",
        " \n",
        " \n",
        "import matplotlib.pyplot as plt \n",
        " \n",
        "plt.figure(figsize=(5,5)) \n",
        "plt.imshow(img) \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsgdoM7ylWIK"
      },
      "source": [
        "# widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yEKZYOlHggmW"
      },
      "outputs": [],
      "source": [
        "#@title youtube jukebox { form-width: \"200px\" }\n",
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "jukebox = {\"The Dead South - In Hell I'll Be In Good Company\"   :\"B9FzVhw8_bY\",\n",
        "           \"Big Bad Voodoo Daddy - Why Me?\"                     :\"a3Z4RWZa9WA\",\n",
        "           \"Kishi Bashi - Violin Tsunami\"                       :\"xlXwpaAVoJQ\",\n",
        "           \"Jamie T - Sheila\"                                   :\"4-L7Cadb-c0\",\n",
        "           \"Tash Sultana - Jungle\"                              :\"1ExkpBpYEPw\"}\n",
        "\n",
        "select = \"The Dead South - In Hell I'll Be In Good Company\" #@param [\"The Dead South - In Hell I'll Be In Good Company\",\"Big Bad Voodoo Daddy - Why Me?\",\"Kishi Bashi - Violin Tsunami\",\"Jamie T - Sheila\",\"Tash Sultana - Jungle\"]\n",
        "\n",
        "display ( YouTubeVideo ( jukebox [ select ] ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v0-4n5we0JoV"
      },
      "outputs": [],
      "source": [
        "#@title radio buttons\n",
        "import ipywidgets as widgets\n",
        "import numpy\n",
        "\n",
        "\n",
        "output_radio_selected = widgets.Text()\n",
        "radio1 = widgets.RadioButtons(options=['mse'])\n",
        "radio2 = widgets.RadioButtons(options=['mae'])\n",
        "\n",
        "radio1.index = None\n",
        "radio2.index = None\n",
        "\n",
        "def radio1_observer(sender):\n",
        "    #print(sender)\n",
        "    radio2.unobserve(radio2_observer, names=['value'])\n",
        "    radio2.index = None\n",
        "\n",
        "    global selected_option\n",
        "    output_radio_selected.value = radio1.value\n",
        "    selected_option = output_radio_selected.value\n",
        "    print('Selected option set to: ' + selected_option)\n",
        "\n",
        "    radio2.observe(radio2_observer, names=['value'])\n",
        "\n",
        "def radio2_observer(sender):\n",
        "    radio1.unobserve(radio1_observer, names=['value'])\n",
        "    radio1.index = None\n",
        "\n",
        "    global selected_option2\n",
        "    output_radio_selected.value = radio2.value\n",
        "    selected_option2 = output_radio_selected.value\n",
        "    print('Selected option set to: ' + selected_option2)\n",
        "\n",
        "    radio1.observe(radio1_observer, names=['value'])\n",
        "\n",
        "\n",
        "radio1.observe(radio1_observer, names=['value'])\n",
        "radio2.observe(radio2_observer, names=['value'])\n",
        "\n",
        "widgets.HBox([radio1,radio2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx1g95w5Ppew"
      },
      "source": [
        "# tex it \n",
        "\n",
        "$$\\large \\sum {\\frac {Frit^z} {\\sqrt[the] {C\\alpha t}} }$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22FYk-PsXmQc"
      },
      "source": [
        "# greek letters\n",
        "\n",
        "<table>\n",
        "<tr><td>Alpha $\\alpha$ / $A$</td><td>Beta $\\beta$ / $B$</td><td>Gamma $\\gamma$ / $\\Gamma$</td><td>Delta $\\delta$ / $\\Delta$</td><td>Epsilon $\\epsilon$ / $E$</td><td>Zeta $\\zeta$ / $Z$</td></tr>\n",
        "\n",
        "<tr><td>Eta $\\eta$ / $E$</td><td>Theta $\\theta$ / $\\Theta$</td><td>Iota $\\iota$ / $I$</td><td>Kappa $\\kappa$ / $K$</td><td>Lambda $\\lambda$ / $\\Lambda$</td><td>My $\\mu$ / $M$</td></tr>\n",
        "\n",
        "<tr><td>Ny $\\nu$ / $N$</td><td>Xi $\\xi$ / $\\Xi$</td><td>Omikron $\\omicron$ / $O$</td><td>Pi $\\pi$ / $\\Pi$</td><td>Rho $\\rho$ / $R$</td><td>Sigma $\\sigma$ / $\\Sigma$</td></tr>\n",
        "\n",
        "<tr><td>Tau $\\tau$ / $T$</td><td>Ypsilon $\\upsilon$ / $\\Upsilon$</td><td>Phi $\\phi$ / $\\Phi$</td><td>Chi $\\chi$ / $X$</td><td>Psi $\\psi$ / $\\Psi$</td><td>Omega $\\omega$ / $\\Omega$</td></tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ZlhGHEQaNm"
      },
      "source": [
        "# ```%linemagic``` and ```%%cellmagic```\n",
        "\n",
        "* [Jupyter's magics page](http://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb) - from the [ipython project](https://github.com/ipython/ipython)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "neLjbfuN-6aJ"
      },
      "outputs": [],
      "source": [
        "#@markdown **list magics**\n",
        "%lsmagic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rmX-ASsV7zFi"
      },
      "outputs": [],
      "source": [
        "#@markdown **bash script**\n",
        "%%bash\n",
        "\n",
        "echo ls\n",
        "ls\n",
        "echo ''\n",
        "echo 'pwd'\n",
        "pwd\n",
        "echo ''\n",
        "echo '$PATH'\n",
        "echo $PATH\n",
        "echo ''\n",
        "echo 'system'\n",
        "cat /etc/os*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bWpCCPIHA9yb"
      },
      "outputs": [],
      "source": [
        "#@markdown **html**\n",
        "%%html\n",
        "\n",
        "<table width=\"700\"><tr><td width=\"200\">\n",
        "  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 450 400\" width=\"200\" height=\"200\">\n",
        "    <rect x=\"80\" y=\"60\" width=\"250\" height=\"250\" rx=\"20\" style=\"fill:red; stroke:black; fill-opacity:0.7\" />\n",
        "    <rect x=\"180\" y=\"110\" width=\"250\" height=\"250\" rx=\"40\" style=\"fill:blue; stroke:black; fill-opacity:0.5;\" />\n",
        "  </svg>\n",
        "</td><td>\n",
        "  <marquee style='width: 30%; color: blue;'><b>Whee!</b></marquee>\n",
        "</td></tr></table>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcIF4IwsKR-x"
      },
      "source": [
        "# gdrive hosting\n",
        "\n",
        "1. Connect your google account. This allows you to save directly to your gdrive from within applications. \n",
        "2. Create new inkscape file (as an example) and save it to you gdrive. (It doesn't work with linux - you have to download, edit, upload) \n",
        "3. Open your gdrive in the browser, right click to the saved file and choose 'release'.\n",
        "4. In the popup under 'general access' choose the option 'anyone who has the link'.\n",
        "5. Copy the link. You will get the wrong format. It looks like <br>\n",
        "```https://drive.google.com/file/d/1cehK_fxj8vtBX1df3aKWF6RSOygzIAiR/view?usp=sharing```\n",
        "6. Change it to the following format: <br> ```https://drive.google.com/uc?id=1cehK_fxj8vtBX1df3aKWF6RSOygzIAiR```\n",
        "7. After reload the notebook in the browser the changes are visible.\n",
        "\n",
        "<br>You can use the link in a ```<img>``` tag<br>\n",
        "<img src='https://drive.google.com/uc?id=1cehK_fxj8vtBX1df3aKWF6RSOygzIAiR' width=\"400\">\n",
        "\n",
        "or you can use it in your code.\n",
        "```python\n",
        "from IPython.display import SVG\n",
        "SVG('https://drive.google.com/uc?id=1cehK_fxj8vtBX1df3aKWF6RSOygzIAiR')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRnt3XweE1L"
      },
      "source": [
        "# inline images\n",
        "\n",
        "1. Insert the html tag in your text cell. It look like this:\n",
        "``` html\n",
        "<div>\n",
        "  <img src=\"<data>\" alt=\"alternative text\"/>\n",
        "</div>\n",
        "```\n",
        "\n",
        "2. Go to an [encoder page](https://www.base64-image.de/) (there are a lot) and generate the data string for your svg / jpg / etc ('copy image' button). \n",
        "3. Replace ```<data>``` with the string inside the quotes. The string have to beginn with <br>```data:image/svg+xml;base64,```\n",
        "<div><img width=\"400\" src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   width="210.20558mm"
   height="75.663567mm"
   viewBox="0 0 210.20558 75.663566"
   version="1.1"
   id="svg8"
   inkscape:version="0.92.5 (2060ec1f9f, 2020-04-08)"
   sodipodi:docname="mccullochpitts.svg">
  <defs
     id="defs2">
    <marker
       inkscape:stockid="Arrow2Lend"
       orient="auto"
       refY="0"
       refX="0"
       id="marker5360"
       style="overflow:visible"
       inkscape:isstock="true">
      <path
         id="path5358"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.625;stroke-linejoin:round;stroke-opacity:1"
         d="M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z"
         transform="matrix(-1.1,0,0,-1.1,-1.1,0)"
         inkscape:connector-curvature="0" />
    </marker>
    <marker
       inkscape:isstock="true"
       style="overflow:visible"
       id="marker5284"
       refX="0"
       refY="0"
       orient="auto"
       inkscape:stockid="Arrow2Lend"
       inkscape:collect="always">
      <path
         transform="matrix(-1.1,0,0,-1.1,-1.1,0)"
         d="M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.625;stroke-linejoin:round;stroke-opacity:1"
         id="path5282"
         inkscape:connector-curvature="0" />
    </marker>
    <marker
       inkscape:stockid="Arrow2Lend"
       orient="auto"
       refY="0"
       refX="0"
       id="marker5236"
       style="overflow:visible"
       inkscape:isstock="true"
       inkscape:collect="always">
      <path
         id="path5234"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.625;stroke-linejoin:round;stroke-opacity:1"
         d="M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z"
         transform="matrix(-1.1,0,0,-1.1,-1.1,0)"
         inkscape:connector-curvature="0" />
    </marker>
    <marker
       inkscape:isstock="true"
       style="overflow:visible"
       id="marker5194"
       refX="0"
       refY="0"
       orient="auto"
       inkscape:stockid="Arrow2Lend"
       inkscape:collect="always">
      <path
         transform="matrix(-1.1,0,0,-1.1,-1.1,0)"
         d="M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.625;stroke-linejoin:round;stroke-opacity:1"
         id="path5192"
         inkscape:connector-curvature="0" />
    </marker>
    <marker
       inkscape:stockid="Arrow2Lend"
       orient="auto"
       refY="0"
       refX="0"
       id="Arrow2Lend"
       style="overflow:visible"
       inkscape:isstock="true"
       inkscape:collect="always">
      <path
         id="path4543"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.625;stroke-linejoin:round;stroke-opacity:1"
         d="M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z"
         transform="matrix(-1.1,0,0,-1.1,-1.1,0)"
         inkscape:connector-curvature="0" />
    </marker>
    <marker
       inkscape:stockid="Arrow1Lend"
       orient="auto"
       refY="0"
       refX="0"
       id="Arrow1Lend"
       style="overflow:visible"
       inkscape:isstock="true">
      <path
         id="path4525"
         d="M 0,0 5,-5 -12.5,0 5,5 Z"
         style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:1.00000003pt;stroke-opacity:1"
         transform="matrix(-0.8,0,0,-0.8,-10,0)"
         inkscape:connector-curvature="0" />
    </marker>
  </defs>
  <sodipodi:namedview
     id="base"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:pageopacity="0.0"
     inkscape:pageshadow="2"
     inkscape:zoom="0.76"
     inkscape:cx="15.940481"
     inkscape:cy="97.795995"
     inkscape:document-units="mm"
     inkscape:current-layer="layer1"
     showgrid="true"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:window-width="1848"
     inkscape:window-height="1016"
     inkscape:window-x="1122"
     inkscape:window-y="221"
     inkscape:window-maximized="1">
    <inkscape:grid
       type="xygrid"
       id="grid10"
       originx="-42.638221"
       originy="-169.68149" />
  </sodipodi:namedview>
  <metadata
     id="metadata5">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <g
     inkscape:label="Ebene 1"
     inkscape:groupmode="layer"
     id="layer1"
     transform="translate(-42.638222,-51.654968)">
    <circle
       style="fill:none;stroke:#000000;stroke-width:0.565;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       id="path4830"
       cx="110.84649"
       cy="87.66272"
       r="15.875" />
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="41.67704"
       y="60.991661"
       id="text5110"><tspan
         sodipodi:role="line"
         id="tspan5108"
         x="41.67704"
         y="60.991661"
         style="stroke-width:0.26458332">b</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="42.333332"
       y="74.53569"
       id="text5114"><tspan
         sodipodi:role="line"
         id="tspan5112"
         x="42.333332"
         y="74.53569"
         style="stroke-width:0.26458332"
         dy="0 0">x<tspan
   style="font-size:64.99999762%;baseline-shift:sub"
   id="tspan5124">1</tspan></tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="42.333332"
       y="90.18969"
       id="text5118"><tspan
         sodipodi:role="line"
         id="tspan5116"
         x="42.333332"
         y="90.18969"
         style="stroke-width:0.26458332">x<tspan
   style="font-size:64.99999762%;baseline-shift:sub"
   id="tspan5126">2</tspan></tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="42.333332"
       y="121.49773"
       id="text5122"><tspan
         sodipodi:role="line"
         id="tspan5120"
         x="42.333332"
         y="121.49773"
         style="stroke-width:0.26458332">x<tspan
   style="font-size:64.99999762%;baseline-shift:sub"
   id="tspan5128">n</tspan></tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="41.506508"
       y="104.66448"
       id="text5132"><tspan
         sodipodi:role="line"
         id="tspan5130"
         x="41.506508"
         y="104.66448"
         style="stroke-width:0.26458332">...</tspan></text>
    <path
       style="opacity:0.95999995;fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;marker-end:url(#Arrow2Lend)"
       d="m 52.916666,55.699995 c 42.333333,31.75 42.333333,31.75 42.333333,31.75"
       id="path5134"
       inkscape:connector-curvature="0" />
    <path
       style="fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;marker-end:url(#marker5194)"
       d="m 52.916666,71.574995 c 42.333333,15.875 42.333333,15.875 42.333333,15.875"
       id="path5184"
       inkscape:connector-curvature="0" />
    <path
       style="fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;marker-end:url(#marker5236)"
       d="m 52.916666,87.449995 c 42.333333,0 42.333333,0 42.333333,0"
       id="path5226"
       inkscape:connector-curvature="0" />
    <path
       style="fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;marker-end:url(#marker5284)"
       d="M 52.916666,119.19995 C 95.249999,87.449995 95.249999,87.449995 95.249999,87.449995"
       id="path5274"
       inkscape:connector-curvature="0" />
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="99.984642"
       y="90.654404"
       id="text5342"><tspan
         sodipodi:role="line"
         id="tspan5340"
         x="99.984642"
         y="90.654404"
         style="stroke-width:0.26458332">g</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="116.34704"
       y="91.753548"
       id="text5346"><tspan
         sodipodi:role="line"
         id="tspan5344"
         x="116.34704"
         y="91.753548"
         style="stroke-width:0.26458332">f</tspan></text>
    <path
       style="fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       d="m 111.125,71.574995 c 0,31.749955 0,31.749955 0,31.749955"
       id="path5348"
       inkscape:connector-curvature="0" />
    <path
       style="fill:none;stroke:#000000;stroke-width:0.465;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;marker-end:url(#marker5360)"
       d="m 127,87.449995 c 15.875,0 15.875,0 15.875,0"
       id="path5350"
       inkscape:connector-curvature="0" />
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:10.58333302px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
       x="147.4704"
       y="90.722473"
       id="text5412"><tspan
         sodipodi:role="line"
         id="tspan5410"
         x="147.4704"
         y="90.722473"
         style="stroke-width:0.26458332">f( g(b,x1,x2,...,xn) )</tspan></text>
    <flowRoot
       xml:space="preserve"
       id="flowRoot926"
       style="font-style:normal;font-weight:normal;font-size:40px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none"
       transform="matrix(0.26458333,0,0,0.26458333,42.638222,53.417511)"><flowRegion
         id="flowRegion928"><rect
           id="rect930"
           width="960"
           height="600"
           x="-121.15233"
           y="-119.3731" /></flowRegion><flowPara
         id="flowPara932"></flowPara></flowRoot>    <flowRoot
       xml:space="preserve"
       id="flowRoot934"
       style="font-style:normal;font-weight:normal;font-size:40px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none"
       transform="matrix(0.26458333,0,0,0.26458333,42.638222,53.417511)"><flowRegion
         id="flowRegion936"><rect
           id="rect938"
           width="900"
           height="460"
           x="-61.152332"
           y="-59.3731" /></flowRegion><flowPara
         id="flowPara940"></flowPara></flowRoot>  </g>
</svg>
\" alt=\"svg\" /></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MOcPDdqvGgBq"
      },
      "outputs": [],
      "source": [
        "#@markdown svg with graphviz\n",
        "import graphviz\n",
        "s='init->predict->loss->gradient->step->stop\\nstep->predict[label=repeat]'\n",
        "graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}