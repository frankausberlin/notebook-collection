{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyZ2k3pRDNkAXy1jlNO5RA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankausberlin/notebook-collection/blob/main/neuralnetworknotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Neural Network Notebook\n",
        "\n",
        "This is a little cheat sheet to describe the essence of what is called a (**feed forward**) **neural network**.\n",
        "\n",
        "To understand you have to know some basic concepts which you can find around a bunch of keywords - these are the most important: \n",
        "\n",
        "<table width='600'>\n",
        "<tr><td><p><b>Perceptron<br><br>Parameter</td><td><p><b>Data<br><br>Batches</td><td><p><b>Layer<br><br>Model</td><td><p><b>Training<br><br>Optimizer</td><td><p><b>Loss<br><br>Metric</td></tr>\n",
        "<tr><td colspan=5>In the following, further <b>keywords</b> are shown in bold type.</td></tr>\n",
        "</table><br>\n",
        "\n",
        "I use Pytorch as library. The self-made classes serves to improve understanding. These are limited to the basic functionality and are to be seen as excerpts from the library classes.\n"
      ],
      "metadata": {
        "id": "ekEFR0k4uNLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron & Parameter\n",
        "\n",
        "<table>\n",
        "<tr><td>\n",
        "<img src='https://drive.google.com/uc?id=1cehK_fxj8vtBX1df3aKWF6RSOygzIAiR' width=\"300\">\n",
        "</td><td>\n",
        "\n",
        "* A Perceptron gets a **stimulation** $s()$ and do an **activation** $a()$.<br><br>\n",
        "* The stimulation is a function which maps a lot of x to one y.<br> \n",
        "$y=s(x_1,x_2,...,x_n)$<br><br>\n",
        "* The Perceptron provides **parameters** for that function: **weights**<br> for every x and one **bias**. <br>$y=x_1w_1+x_2w_2+...+x_nw_n+b$<br><br>\n",
        "* The activation is an other function that gets the result of the<br>stimulation and bring it in a special form (**sigmoid**, **ReLU** etc.).<br>$y = a(s(x))$<br>\n",
        "</td></tr>\n",
        "<tabel>\n",
        "\n",
        "<table><tr></tr><tr><td><img src='https://drive.google.com/uc?id=1wpQFjcKY7jrAPXr5yUF_spOn4eK9yjDB' width=\"12\"></td><td>threshold symbol &emsp;&emsp;'$\\bullet$': dot symbol ($x\\bullet w+b$; in python: <i>x@weights + bias)</i></td></tr></table>\n"
      ],
      "metadata": {
        "id": "XEK_lPNE1zUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09e8Lu4htoxL",
        "outputId": "d68552ed-4cea-491c-f150-483933d822e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3457])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from torch import randn, tensor, sigmoid, manual_seed\n",
        "manual_seed (0)\n",
        "\n",
        "class Perceptron:\n",
        "  bias, weights, activation = None, None, None\n",
        "\n",
        "  def __init__(self, signals, activation=lambda x:x):\n",
        "    self.weights, self.bias, self.activation = randn (signals), randn (1), activation\n",
        "\n",
        "  def __call__ (self,x): \n",
        "    return self.activation ( x@self.weights + self.bias )\n",
        "\n",
        "# usage\n",
        "p = Perceptron (2,sigmoid)\n",
        "x = tensor ([1.0, 0.0])\n",
        "p(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data & Batches\n",
        "\n",
        "In **supervised** learning you have **datasets**. That are pairs of input data with its **labels**. The input data are also called **features**. \n",
        "\n",
        "* The features and labels must often be converted into a special format (**normalization**, **categories**, **scaling** etc.)\n",
        "* To train a neural network we need the data in a special structur: the **batches**.\n",
        "* A batch is a small chunk of data set with a defined **batch size**, mostly shuffled.\n",
        "* The batch is the input for one **step** of the optimization process.\n",
        "\n",
        "**Example Data**\n",
        "\n",
        "* As example we use the **mnist** dataset. It includes 60000 **training** and 10000 **validation** datasets.\n",
        "* The input are 28x28 pixel pictures of hand written digits and the corresponding label (a number between 0 and 9).\n",
        "* The labels (or expected) are numbers and will be **one-hot-encoded**. That means:\n",
        ">0 --> 1000000000<br>7 --> 0000000100 usw.\n",
        "\n"
      ],
      "metadata": {
        "id": "2qe8Fin-28qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import                       random, torch, numpy as np\n",
        "from matplotlib      import  pyplot as plt\n",
        "from torchvision     import  datasets\n",
        "\n",
        "class Batches:\n",
        "  batches    = None\n",
        "  pos        = 0\n",
        "\n",
        "  def __init__(self, XY, batchSize=-1):\n",
        "    complete, self.batches, self.pos = list(zip(*XY)), [], 0\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    random.shuffle (complete)\n",
        "    if batchSize <= 0:\n",
        "      (x,y) = zip (*complete)\n",
        "      self.batches.append ( ( torch.tensor(np.array(x),device=device).reshape((len(x),-1)).float(), \n",
        "                              torch.tensor(np.array(y),device=device).reshape((len(y),-1)).float() ) )\n",
        "    else:\n",
        "      for p in range (0,len(complete),batchSize):\n",
        "        (x,y) = zip (*complete[p:p+batchSize] ) if p+batchSize < len(complete) else zip (*complete[p:])\n",
        "        self.batches.append ( ( torch.tensor(np.array(x),device=device).reshape((len(x),-1)).float(), \n",
        "                                torch.tensor(np.array(y),device=device).reshape((len(y),-1)).float() ) )\n",
        "\n",
        "  def __iter__(self):                   self.pos = 0; return self\n",
        "  def __next__(self): \n",
        "    if self.pos < len (self.batches):   self.pos += 1; return self.batches[self.pos-1]\n",
        "    else:                               self.pos  = 0; raise StopIteration\n",
        "\n",
        "# mnist data\n",
        "ds_train = datasets.MNIST(root=\"data\", train=True, download=True)\n",
        "ds_test  = datasets.MNIST(root=\"data\", train=False, download=True)\n",
        "train    = ds_train.data.numpy(), np.eye(10)[ds_train.targets.numpy()]\n",
        "test     = ds_test.data.numpy(),  np.eye(10)[ds_test.targets.numpy()]\n",
        "x, y     = train\n",
        "\n",
        "# first image and label\n",
        "plt.imshow (x[0], cmap='binary')\n",
        "print ('first image x[0]:',x[0].shape)\n",
        "plt.show ()\n",
        "print ('y[0]:',y[0],f'(the label: {np.where (y[0] == 1.)[0][0]})')\n",
        "\n",
        "# convert data to batches\n",
        "batches       = Batches (train, 100)\n",
        "x, y          = next (batches)\n",
        "for count, b in enumerate(batches): pass\n",
        "print (f'\\ngenerate {count+1} batches with a size of {len(x)}',f'first batch (x, y): {x.shape, y.shape}',sep='\\n')\n",
        "x,y = b\n",
        "print (f'last  batch (x, y): {x.shape, y.shape}',sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "kcfQrZhgJE5O",
        "outputId": "178aa0d3-bde4-4cde-fe67-d912e2be7bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first image x[0]: (28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y[0]: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] (the label: 5)\n",
            "\n",
            "generate 600 batches with a size of 100\n",
            "first batch (x, y): (torch.Size([100, 784]), torch.Size([100, 10]))\n",
            "last  batch (x, y): (torch.Size([100, 784]), torch.Size([100, 10]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Layer & Model\n",
        "\n",
        "There are several ways to implement a perceptron. In the stand-alone version you can put the activation in the Perceptron class. However, if you want a Multi Layer Perceptron (**MLP**), it's better to put them in the Layer class or even provide your own Layer class for it.\n",
        "\n",
        "<table>\n",
        "<tr><td>\n",
        "<img src='https://drive.google.com/uc?id=1CHMToYHABzq5zi0yy3wImEHeInbkaiMG' width=\"600\">\n",
        "</td><td>\n",
        "\n",
        "* The model has one **input** layer, several **hidden** layer<br> and one **output** layer.<br><br>\n",
        "* The input layer is not really a layer, it means the input<br> values aka **signals**.<br><br>\n",
        "* A layer represents one or more **Perceptrons**. Each of<br> them get the input values.<br><br>\n",
        "* The ouptuts of the perceptrons in a layer are the input<br> values for the perceptrons in the next layer.<br> This principle is called <b>feed forward</b>.<br><br>\n",
        "* This is how it looks:\n",
        "\n",
        ">```python\n",
        "x = torch.tensor ([1.0, 2.0]).to('cuda')\n",
        "#\n",
        "\"\"\" pytorch version \"\"\"\n",
        "from torch.nn import Linear, Sequential, Sigmoid\n",
        "model = Sequential( Linear (2,1), Sigmoid() ).to('cuda')\n",
        "y = model (x)\n",
        "#\n",
        "\"\"\" self-made version \"\"\"\n",
        "from torch import sigmoid\n",
        "model = Model ( Perceptrons (2,1,sigmoid) )\n",
        "y = model (x)\n",
        "```\n",
        "</td></tr>\n",
        "<tr><td colspan=2>\n",
        "ps. The <b>deep</b> in Deep Learning means a large number of layers.</td></tr>\n",
        "<tr></tr>\n",
        "<tr><td colspan=2>\n",
        "\n",
        "The code below shows how it works.\n",
        "</td></tr>\n",
        "</tabel>\n",
        "<tr></tr>\n"
      ],
      "metadata": {
        "id": "YNVG7qcURbei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import randn, tensor, sigmoid, manual_seed, stack, squeeze\n",
        "\n",
        "manual_seed (0)\n",
        "\n",
        "class Perceptrons:\n",
        "  weights, bias, activation = None, None, None\n",
        "\n",
        "  def __init__(self, signals, count=1, activation=lambda x:x):\n",
        "    self.activation   = activation\n",
        "    device            = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    #                   transpose: ([signals,count]) => ([count,signals]).T\n",
        "    self.weights      = randn ([signals,count], requires_grad=True, device=device)  \n",
        "    self.bias         = randn ([count],         requires_grad=True, device=device)\n",
        "\n",
        "  def __call__(self, x): return self.activation ( x@self.weights + self.bias )\n",
        "\n",
        "\n",
        "class Model:\n",
        "  layers = None\n",
        "\n",
        "  def __init__(self, *layers):  self.layers = layers\n",
        "\n",
        "  def __call__(self, x): \n",
        "    for l in self.layers: \n",
        "      x = l(x)\n",
        "    return x\n",
        "\n",
        "  def parameters(self):         \n",
        "    for l in self.layers: yield (l.weights); yield (l.bias)\n",
        "\n",
        "m = Model (Perceptrons(2,1,sigmoid))\n",
        "x = tensor ([1.0,2.0]).to('cuda')\n",
        "y = m(x)\n",
        "y"
      ],
      "metadata": {
        "id": "B6xcf0ybBJXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e23f834-4f59-4c35-cf2d-c82bff4cfe61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1687], device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Optimizer\n",
        "In the training you do a **prediction** and compare that with the **expected**. We agree on the following terminology:<br>\n",
        ">$\\boldsymbol{\\large{y = predicted = target}=}$ ```y``` <br>\n",
        "$\\boldsymbol{\\large{\\hat{y} = expected = actual}=}$ ```y_```<br>\n",
        "\n",
        "<table><tr><td>\n",
        "<img src='https://drive.google.com/uc?id=1oPqWbq6C-DVn2oQ5HzG-NwynY-Vch16u'>\n",
        "</td><td><p>\n",
        "\n",
        "* The optimizer takes a batch of data and calculates for each<br> dataset in it the change values for all parameters of the model.<br><br>\n",
        "* The **loss** function uses the predicted and the expected values to calculate<br> an error, which is used to determine the change value. <br><br>\n",
        "* The **gradient** is the partial derivative of the loss function with<br> respect to a single parameter.<br><br>\n",
        "* The gradient determines the direction (+ or -) of the weight change,<br> the **learning rate** the size of the change.<br><br>\n",
        "* It adds up the change values and finally changes the parameters.<br> This is called the optimization **step**.<br><br>\n",
        "* The changes aim to improve the results of the model.This <br>optimization process is called **training**. <br><br>\n",
        "* If all batches are completely processed, we speak of a <br>training **epoch**.\n",
        "</td width=\"400\"></tr>\n",
        "</table>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J1NfMnUx4Mcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import sigmoid, randn, tensor, manual_seed, stack, squeeze, nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Optimizer:\n",
        "  params, lr = None, None\n",
        "  def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
        "\n",
        "  def step(self, *args, **kwargs): \n",
        "    for p in self.params: \n",
        "      p.data -= p.grad.data * self.lr\n",
        "\n",
        "  def zero_grad(self, *args, **kwargs): \n",
        "    for p in self.params: p.grad = None \n",
        "\n",
        "\n",
        "def training(epochs, model, batches, optimizer, loss_fn, metric=lambda a,t:''):\n",
        "  for epoch in range(epochs):\n",
        "    for x, y_ in batches:\n",
        "      y               = model (x)\n",
        "      loss            = loss_fn (y, y_) # the loss is base for backward\n",
        "      optimizer       . zero_grad ()\n",
        "      loss            . backward ()\n",
        "      optimizer       . step ()\n",
        "\n",
        "    if not epoch%10:  print (epoch, loss.item(), metric (y,y_)) # the metic is not\n",
        "  print (epoch, loss.item(), metric (y,y_))    \n",
        "\n",
        "m = Model (Perceptrons (28*28, 100, sigmoid), Perceptrons (100, 10) )\n",
        "\n",
        "print ('only a loss function is missing for training - so let\\'s look to the parameters\\n')\n",
        "print ('the parameters() funtction returns a generator, it alternately delivers weights and bias\\n')\n",
        "for p in m.parameters(): print (p.shape)"
      ],
      "metadata": {
        "id": "qzgKtk-oU_kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61327e7f-4beb-43fb-898d-ccb9dd17161d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only a loss function is missing for training - so let's look to the parameters\n",
            "\n",
            "the parameters() funtction returns a generator, it alternately delivers weights and bias\n",
            "\n",
            "torch.Size([784, 100])\n",
            "torch.Size([100])\n",
            "torch.Size([100, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss & Metric\n",
        "\n",
        "The **loss function** is used in training. It must be able to recognize by what amount the change in parameters has improved or degraded the model. The key **difference between loss and metric** is: the loss function is the basis for the **backward** function and is involved in the calculation of the change values - the metric function is not, it evaluates the model after an optimization step or after an epoch. The backward function is a **backpropagation algorithm** which implements the **delta rule**. I would like to mention here the **universal approximation theorem**, which is one of the theoretical foundations of **machine learning**.\n",
        "\n",
        "* Imagine you have the picture of a three ($x$) with its label ($\\hat y$, expected) and you do a prediction ($y$, predicted):<br>\n",
        "<table>\n",
        "<tr><td><p>expected: [</td><td>0.</td><td>0.</td><td>0.</td><td><b>1.</b></td><td>0.</td><td>0.</td><td>0.</td><td>0.</td><td>0.</td><td>0.</td><td><p>]</td></tr><tr></tr>\n",
        "<tr><td><p>predicted: [</td><td>0.1</td><td>0.2</td><td>0.1</td><td><b>0.8</b></td><td>0.1</td><td>0.3</td><td>0.4</td><td>0.2</td><td>0.1</td><td>0.3</td><td><p>]</td></tr>\n",
        "</table>\n",
        "* We can implement a loss function that works like this:<br>\n",
        ">```np.where (expected==1, 1-predicted, predicted)```<br><br>\n",
        "This code snippet generate error values by taking elementwise the expected and:<br>\n",
        ">* when the expected is zero the predicted value is the error value. (consider: first predicted is 0.1 away from the expected 0)\n",
        ">* when the expected is one the error is 1-predicted value. (consider: the fourth predicted is 0.8 - that means it is 0.2 away from the expected 1)\n",
        ">* This only works with values between 0 and 1 (sigmoid).\n",
        "<table><tr><td><p>error: [</td><td>0.1</td><td>0.2</td><td>0.1</td><td><b>0.2</b></td><td>0.1</td><td>0.3</td><td>0.4</td><td>0.2</td><td>0.1</td><td>0.3</td><td><p>]</td></tr></table>\n",
        "\n",
        "* Finaly we can use that snippet and calculate the mean.<br>\n",
        "```python\n",
        "predicted = predicted.sigmoid () # to ensure that all values are between 0 and 1\n",
        "np.where (expected==1, 1-predicted, predicted).mean() # = 0.2\n",
        "```\n",
        "We have a loss function.<br><br>\n",
        "\n",
        "\n",
        "The **metric** function measures the performance of the model - i.e. what percentage is correct. This is easy:\n",
        "\n",
        "$$\n",
        "\\frac{<count \\quad corrects> \\cdot \\; 100}{<count \\quad total>}\n",
        "$$\n",
        "\n",
        "* With the snippet \"```argmax( ... )```\" the one-hot-encoded values will be converted in to a number.\n",
        "```python\n",
        "sum( [argmax(y_) == argmax(y) \n",
        "        for y_, y in zip (expected,predicted) ] ).item()\n",
        " * 100 / len(actual)\n",
        "```\n",
        "* Now we can implement a metric called batch_accuracy:\n",
        "```python\n",
        "batch_accuracy (predicted, expected)\n",
        "```"
      ],
      "metadata": {
        "id": "70gwN72G_T6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import argmax \n",
        "\n",
        "def mnist_loss (predicted, expected):\n",
        "  predicted = predicted.sigmoid ()\n",
        "  return torch.where (expected==1, 1-predicted, predicted).mean()\n",
        "\n",
        "def batch_accuracy (predicted, expected):\n",
        "  return round( sum( [argmax(y_) == argmax(y) \n",
        "                      for y_, y in zip (expected,predicted)] ).item()\n",
        "                * 100 / len(predicted), 2 )\n",
        "  \n",
        "\n",
        "m = Model (Perceptrons (28*28, 100, sigmoid), Perceptrons (100, 10) )\n",
        "b = Batches (train,100)\n",
        "o = Optimizer (m.parameters(),0.1)\n",
        "\n",
        "#training(50, m, b, o, mnist_loss, batch_accuracy)\n",
        "training(100, m, b, o, nn.CrossEntropyLoss(), batch_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCLIBDZ37UhC",
        "outputId": "819f1fcc-267b-43d3-b961-c1c63ae81693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.1259549856185913 65.0\n",
            "10 0.45471101999282837 85.0\n",
            "20 0.5129097700119019 81.0\n",
            "30 0.37102362513542175 87.0\n",
            "40 0.27018818259239197 90.0\n",
            "50 0.27025148272514343 91.0\n",
            "60 0.24779939651489258 92.0\n",
            "70 0.2994755804538727 91.0\n",
            "80 0.280507355928421 92.0\n",
            "90 0.34005218744277954 91.0\n",
            "99 0.32663920521736145 89.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see our model is really bad. Well, this model wasn't made to perform well, it was made to show how neural networks work. For a usable mnist model we need a convolutional neural network (**CNN**)."
      ],
      "metadata": {
        "id": "RQIIZAmORviK"
      }
    }
  ]
}